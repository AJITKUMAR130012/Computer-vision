# -*- coding: utf-8 -*-
"""LogoMatch_encoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I-DhXogOR6EBRbiGUH4JBwPMBa9LTlBP
"""

!git clone https://github.com/AJITKUMAR130012/Computer-vision.git

!ls

cd Computer-vision/

ls

cd Assignment2

ls

import os
import random
import pandas as pd
import numpy as np

path="./Dataset/Problem-1/logo matching/Ex1/logos/"

l=os.listdir(path)
print(len(l))

m=[]
for i in range(len(l)):
    m.append(l[i])
    m.append(l[i])
k=0
for i in range(len(l)):
    id=random.randint(0, len(l)-1)
    m.insert(2*i+2+k, l[id])
    k=k+1

print(len(m))
m

def to_matrix(l, n):
    return [l[i:i+n] for i in range(0, len(l), n)]

m=to_matrix(m,3)

c=np.array(m)
c.dtype

c.shape

df=pd.DataFrame(data=c,columns=['Anchor','Positive','Negative'])

df.sample(5)

!pip install segmentation-models-pytorch
!pip install -U git+https://github.com/albumentations-team/albumentations
!pip install --upgrade opencv-contrib-python

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
import torch 
import timm

import torch.nn.functional as F 
from torch import nn 
from torch.utils.data import Dataset, DataLoader 

from skimage import io
from sklearn.model_selection import train_test_split 

from tqdm import tqdm

DATA_DIR="/content/Computer-vision/Assignment2/Dataset/Problem-1/logo matching/Ex1/logos/"
BAtch_size=1
LR=0.001
EPOCHS=15
DEVICE='cuda'

row=df.iloc[4]
print(row)
print(row.Anchor)

Anchor_img=io.imread(DATA_DIR+row.Anchor)
Negative_img=io.imread(DATA_DIR+row.Negative)
Positive_img=io.imread(DATA_DIR+row.Positive)

io.imshow(Anchor_img)
plt.show()
io.imshow(Negative_img)
plt.show()
io.imshow(Positive_img)
plt.show()

train_df, valid_df=train_test_split(df,test_size=0.20,random_state=42)

train_df.shape, valid_df.shape

class APN_Dataset(Dataset):

  def __init__(self,df):
    self.df=df

  def __len__(self):
    return self.df.shape[0]

  def __getitem__(self,idx):
    row=self.df.iloc[idx]
    A_img=io.imread(DATA_DIR+row.Anchor)
    N_img=io.imread(DATA_DIR+row.Negative)
    P_img=io.imread(DATA_DIR+row.Positive)

    A_img=torch.from_numpy(A_img).permute(2,0,1)/255.0
    P_img=torch.from_numpy(P_img).permute(2,0,1)/255.0
    N_img=torch.from_numpy(N_img).permute(2,0,1)/255.0


    return A_img, P_img, N_img

trainset=APN_Dataset(train_df)
validset=APN_Dataset(valid_df)

len(trainset), len(validset)

idx = 2
A,P,N = trainset[idx]

f, (ax1, ax2, ax3) = plt.subplots(1,3,figsize= (10,5))

ax1.set_title('Anchor')
ax1.imshow(A.numpy().transpose((1,2,0)), cmap = 'gray')

ax2.set_title('Positive')
ax2.imshow(P.numpy().transpose((1,2,0)), cmap = 'gray')

ax3.set_title('Negative')
ax3.imshow(N.numpy().transpose((1,2,0)), cmap = 'gray')

trainloader=DataLoader(trainset,batch_size=BAtch_size, shuffle=True) 
validloader=DataLoader(validset, batch_size=BAtch_size)

print(f"No. of batches in trainloader : {len(trainloader)}")
print(f"No. of batches in validloader : {len(validloader)}")

for A,P,N in trainloader:
  break
    
print(f"One image batch shape : {A.shape}")

efficientnet=timm.create_model('efficientnet_b0', pretrained='True')

efficientnet.classifier

class APN_Model(nn.Module):
  def __init__(self,emb_size=512):
    super(APN_Model, self).__init__()

    self.efficientnet=timm.create_model('efficientnet_b0', pretrained='True')
    self.efficientnet.classifier=nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)

  def forward(self,images):
    embeddings=self.efficientnet(images)
    return embeddings

model=APN_Model()
model.to(DEVICE);

def train_fn(model, dataloader, optimizer, criterion):
  model.train()    # ONN Dropout Layer
  total_loss=0.0
  for A, P, N in tqdm(dataloader):
    A,P,N=A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)
    A_embs=model(A)
    P_embs=model(P)
    N_embs=model(N)

    loss=criterion(A_embs,P_embs,N_embs)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    total_loss+=loss.item()
  return total_loss/len(dataloader)

def eval_fn(model, dataloader, criterion):
  model.eval()     # Off dropout layer
  total_loss=0.0
  for A, P, N in tqdm(dataloader):
    A,P,N=A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)

    A_embs=model(A)
    P_embs=model(P)
    N_embs=model(N)
    loss=criterion(A_embs,P_embs,N_embs)
    total_loss+=loss.item()
  
  return total_loss

criterion=nn.TripletMarginLoss()
optimizer=torch.optim.Adam(model.parameters(), lr=LR)

best_valid_loss=np.Inf
for i in range (EPOCHS):
  train_loss=train_fn(model,trainloader,optimizer,criterion) 
  valid_loss=eval_fn(model,validloader, criterion)

  if valid_loss < best_valid_loss:
    torch.save(model.state_dict(), 'best_model.pt')
    best_valid_loss=valid_loss
    print("Saved_weight_success")
  print(f"Epochs : {i+1} train_loss : {train_loss} valid_loss : {valid_loss}")

def get_encoding_csv(model,anc_img_names):
  anc_img_names_arr=np.array(anc_img_names)
  encodings=[]
  model.eval()    #because no dropout layer
  with torch.no_grad():
    for i in tqdm(anc_img_names_arr):
      A=io.imread(DATA_DIR+i)
      A=torch.from_numpy(A).permute(2,0,1) /255.0
      A=A.to(DEVICE)

      A_enc=model(A.unsqueeze(0))      #(c,w,h)   --> (b,c,w,h)
      encodings.append(A_enc.squeeze().cpu().detach().numpy())
    encodings=np.array(encodings)
    encodings=pd.DataFrame(encodings)
    df_enc=pd.concat([anc_img_names, encodings], axis=1)
  
  return df_enc

model.load_state_dict(torch.load('best_model.pt'))
df_enc=get_encoding_csv(model, df['Anchor'])

df_enc.to_csv('database.csv', index=False)
df_enc.head()

def euclidean_dist(img_enc, anc_enc_arr):
  dist=np.sqrt(np.dot(img_enc-anc_enc_arr,(img_enc-anc_enc_arr).T))
  return dist

idx=2
img_name=df_enc['Anchor'].iloc[idx]
img_path=DATA_DIR+  img_name

#img=io.imread("/content/Computer-vision/Assignment2/Dataset/Problem-1/logo matching/Ex1/levis1.jpg")
img=io.imread(img_path)
img=torch.from_numpy(img).permute(2,0,1) / 255.0
model.eval()

with torch.no_grad():
  img=img.to(DEVICE)
  img_enc=model(img.unsqueeze(0))
  img_enc=img_enc.detach().cpu().numpy()

# c= df_enc.iloc[:,1:]
# print(c)
# print(c[0])
# print(c[0][0])
# print(c[0][1])

# encoding for the anchor image
anc_enc_arr=df_enc.iloc[:,1:].to_numpy()
# Anchor image names
anc_img_names=df_enc['Anchor']

#anc_enc_arr.shape

distance=[]
for i in range(anc_enc_arr.shape[0]):
  dist=euclidean_dist(img_enc, anc_enc_arr[i: i+1, :])
  distance=np.append(distance,dist)

anc_img_names

print(distance)