{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 01:25:46.905554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /scratch/apps/python/3.7/lib/python3.7/site-packages/cv2/../../lib64:/scratch/apps/python/3.7/lib:/opt/ohpc/pub/mpi/libfabric/1.11.2/lib:/opt/ohpc/pub/mpi/ucx-ohpc/1.9.0/lib:/opt/ohpc/pub/mpi/openmpi4-gnu9/4.0.5/lib:/opt/ohpc/pub/compiler/gcc/9.3.0/lib64\n",
      "2023-04-10 01:25:46.905623: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CIFAR-10 dataset\n",
    "from keras.datasets import cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract SIFT features from training images\n",
    "sift = cv2.SIFT_create()\n",
    "train_features = []\n",
    "for img in train_images:\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    if des is not None:\n",
    "        train_features.append(des)\n",
    "train_features = np.vstack(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cluster features using k-means\n",
    "kmeans = KMeans(n_clusters=100).fit(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate visual word histograms for training images\n",
    "train_histograms = []\n",
    "for img in train_images:\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    histogram = np.zeros(100)\n",
    "    if des is not None:\n",
    "        words = kmeans.predict(des)\n",
    "        for word in words:\n",
    "            histogram[word] += 1\n",
    "    train_histograms.append(histogram)\n",
    "train_histograms = np.vstack(train_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize histograms\n",
    "train_histograms = normalize(train_histograms, norm='l2')\n",
    "\n",
    "# Train classifier\n",
    "clf = LinearSVC().fit(train_histograms, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT features from test image\n",
    "test_feature = []\n",
    "kp, des = sift.detectAndCompute(test_images[0], None)\n",
    "test_feature.append(des)\n",
    "test_feature = np.vstack(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate visual word histogram for test image\n",
    "test_histogram = np.zeros(100)\n",
    "if test_feature is not None:\n",
    "    words = kmeans.predict(test_feature)\n",
    "    for word in words:\n",
    "        test_histogram[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize histogram\n",
    "test_histogram = normalize(test_histogram.reshape(1, -1), norm='l2')\n",
    "\n",
    "# Predict class of test image\n",
    "predicted_class = clf.predict(test_histogram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Retrieve top-5 most similar images to test image\n",
    "test_histograms = np.vstack([test_histogram]*len(train_images))\n",
    "distances = np.linalg.norm(train_histograms - test_histograms, axis=1)\n",
    "sorted_indices = np.argsort(distances)[:5]\n",
    "similar_images = train_images[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate precision, recall, and average precision\n",
    "precision, recall, _ = precision_recall_curve(test_labels, predicted_class)\n",
    "ap = average_precision_score(test_labels, predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot precision-recall curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall, precision, color='b', label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall for CIFAR-10')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"AP: \", ap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
